{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\practise\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\anaconda3\\envs\\practise\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\anaconda3\\envs\\practise\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\anaconda3\\envs\\practise\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\anaconda3\\envs\\practise\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\anaconda3\\envs\\practise\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        with tf.variable_scope('inputs'):\n",
    "            self.x = tf.placeholder(tf.float32,[None],name='input_x')\n",
    "            self.y = tf.placeholder(tf.float32,[None],name='output_y')\n",
    "        \n",
    "    def initialize(self):\n",
    "        with tf.variable_scope('hidden_layer'):\n",
    "            self.W = tf.Variable([1.0], dtype=tf.float32,name='W')\n",
    "            self.b = tf.Variable([1.0],dtype=tf.float32,name='b')\n",
    "            \n",
    "            self.y_hat = tf.add(tf.multiply(self.x,self.W,name='Wx'), self.b, name='b')\n",
    "            \n",
    "        print('No. of trainable variables : {}'.format(np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])))\n",
    "\n",
    "    def add_loss(self):\n",
    "        with tf.variable_scope('loss'):\n",
    "            self.loss = tf.reduce_mean(tf.squared_difference(self.y, self.y_hat))\n",
    "            \n",
    "    def add_optimizer(self,global_step,learning_rate=1.e-3,adam_beta1=0.9,adam_beta2=0.999):\n",
    "        with tf.variable_scope('optimizer'):\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate, adam_beta1, adam_beta2)\n",
    "            gradients, variables = zip(*optimizer.compute_gradients(self.loss))\n",
    "            self.gradients = gradients\n",
    "            clipped_gradients, _ = tf.clip_by_global_norm(gradients, 1.0)\n",
    "            with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "                self.optimize = optimizer.apply_gradients(zip(clipped_gradients, variables),global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\anaconda3\\envs\\practise\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "No. of trainable variables : 2\n"
     ]
    }
   ],
   "source": [
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "model = Model()\n",
    "model.initialize()\n",
    "model.add_loss()\n",
    "model.add_optimizer(global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(50,)\n",
    "y = 3.0 * x + 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.53942634,  1.45199584,  1.12428659, -1.17683331,  0.39828799,\n",
       "        0.81691035, -2.36374788,  0.60732233, -0.12366254, -0.54987721,\n",
       "       -0.15468642,  0.51275471,  0.66754244,  0.92455115, -0.09795126,\n",
       "       -1.2652552 ,  0.77645818,  0.80935877, -1.03700587, -0.25661369,\n",
       "       -0.92931889, -0.75452206, -0.20818565,  0.91042222, -1.04288034,\n",
       "        0.96265468,  0.10041513, -0.86387517,  2.10921583, -0.50501554,\n",
       "       -0.67053802,  0.0864083 , -1.21288896,  1.66420075, -0.97103521,\n",
       "        0.14055298, -1.6944407 , -0.55859434, -0.12428911, -0.07062646,\n",
       "       -0.3257712 , -0.26491217, -0.30052856, -0.37497409, -1.32759124,\n",
       "        0.54552197, -0.9703957 , -0.90949303, -1.84386426, -0.40508839])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.61827902,  9.35598751,  8.37285977,  1.46950007,  6.19486396,\n",
       "        7.45073104, -2.09124365,  6.82196698,  4.62901238,  3.35036838,\n",
       "        4.53594074,  6.53826412,  7.00262732,  7.77365346,  4.70614621,\n",
       "        1.20423439,  7.32937453,  7.4280763 ,  1.8889824 ,  4.23015894,\n",
       "        2.21204334,  2.73643381,  4.37544305,  7.73126666,  1.87135898,\n",
       "        7.88796404,  5.30124538,  2.4083745 , 11.3276475 ,  3.48495339,\n",
       "        2.98838595,  5.25922491,  1.36133311,  9.99260225,  2.08689437,\n",
       "        5.42165893, -0.08332211,  3.32421698,  4.62713267,  4.78812063,\n",
       "        4.02268639,  4.2052635 ,  4.09841433,  3.87507773,  1.01722628,\n",
       "        6.63656591,  2.0888129 ,  2.2715209 , -0.53159278,  3.78473484])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : [500] loss = [12.851274]\n",
      "Step : [1000] loss = [9.126898]\n",
      "Step : [1500] loss = [6.157516]\n",
      "Step : [2000] loss = [3.853718]\n",
      "Step : [2500] loss = [2.127317]\n",
      "Step : [3000] loss = [0.921291]\n",
      "Step : [3500] loss = [0.215660]\n",
      "Step : [4000] loss = [0.025458]\n",
      "Step : [4500] loss = [0.001796]\n",
      "Step : [5000] loss = [0.000059]\n",
      "Step : [5500] loss = [0.000001]\n",
      "Step : [6000] loss = [0.000000]\n",
      "Step : [6500] loss = [0.000000]\n",
      "Step : [7000] loss = [0.000000]\n",
      "Step : [7500] loss = [0.000000]\n",
      "Step : [8000] loss = [0.000000]\n",
      "Step : [8500] loss = [0.000000]\n",
      "Step : [9000] loss = [0.000000]\n",
      "Step : [9500] loss = [0.000000]\n",
      "Step : [10000] loss = [0.000000]\n",
      "Time taken : 6.403891324996948 secs.\n",
      "Learnt Values : W : [2.999999] b : [4.999995]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    start_step = sess.run(global_step)\n",
    "    start_time = time.time()\n",
    "    for _ in range(10000):\n",
    "        step, loss, opt = sess.run([global_step, model.loss, model.optimize],feed_dict={model.x:x,model.y:y})\n",
    "        \n",
    "        if step % 500 == 0:\n",
    "            print('Step : [%d] loss = [%f]' % (step,loss))\n",
    "    print('Time taken : {} secs.'.format(time.time() - start_time))        \n",
    "    print('Learnt Values : W : [%f] b : [%f]' % (sess.run(model.W), sess.run(model.b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
